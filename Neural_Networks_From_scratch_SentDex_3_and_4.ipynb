{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVPV93Mji4m905I4jnKOT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishirajbal/Rishirajbal/blob/main/Neural_Networks_From_scratch_SentDex_3_and_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKzzlT5RL_aN"
      },
      "outputs": [],
      "source": [
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0], [0.4, 0.2, -0.2, 0.5], [0.15, 0.9, -0.4, 0.2]]\n",
        "bias = [2, 1, 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#single weight,single input setup\n",
        "import numpy as np\n",
        "inputs = [1, 2, 3, 2.5]\n",
        "weights =[0.2, 0.8, -0.5, 1.0]\n",
        "bias =2\n",
        "output = np.dot(inputs,weights)+bias\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zN-s4hnb1xE",
        "outputId": "272b2b6b-1cb9-4012-e1f4-9889158f6bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multi-weight,single input setup\n",
        "import numpy as np\n",
        "inputs = [1, 2, 3, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "            [0.4, 0.2, -0.2, 0.5],\n",
        "             [0.15, 0.9, -0.4, 0.2]]\n",
        "bias = [2, 1, 0.5]\n",
        "output=np.dot(weights,inputs)+bias\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L-jdMgBdk_O",
        "outputId": "def0cb66-4949-447d-ff38-012de60e32d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.8  2.45 1.75]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#multi-weight,multi-input setup\n",
        "import numpy as np\n",
        "inputs = [[1, 2, 3, 2.5],\n",
        "           [2.0,5.0,-1.0,2.0],\n",
        "            [-1.5,2.7,3.3,-0.8]]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "            [0.4, 0.2, -0.2, 0.5],\n",
        "             [0.15, 0.9, -0.4, 0.2]]\n",
        "transposed_weights = np.array(weights).T\n",
        "bias = [2,3, 0.5]\n",
        "output=np.dot(inputs ,transposed_weights )+bias\n",
        "print(output)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hWdVBsIoavo",
        "outputId": "5a5065e5-8f28-4f81-9383-781979c67fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.8   4.45  1.75 ]\n",
            " [8.9   6.    6.1  ]\n",
            " [1.41  1.88  1.225]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multi-weight,multi-input,multi layered setup\n",
        "import numpy as np\n",
        "inputs = [[1, 2, 3, 2.5],\n",
        "           [2.0,5.0,-1.0,2.0],\n",
        "            [-1.5,2.7,3.3,-0.8]]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "            [0.4, 0.2, -0.2, 0.5],\n",
        "             [0.15, 0.9, -0.4, 0.2]]\n",
        "bias = [2,3, 0.5]\n",
        "weights2=[[0.1,-0.14,0.5],\n",
        "          [-0.5,0.12,-0.33],\n",
        "           [-0.44,0.73,-0.13]]\n",
        "bias2=[-1,2,-0.5]\n",
        "layer_output1=np.dot(inputs,np.array(weights).T)+bias\n",
        "layer_output2=np.dot(layer_output1,np.array(weights2).T)+bias2 #input_2 = layer_output2 = np.dot(inputs,np.array(weights).T)+bias\n",
        "\n",
        "print(layer_output2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B95mrcaBxMIG",
        "outputId": "326fef94-af7d-43be-fb3d-86dc6610927c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.268   -0.4435   0.409  ]\n",
            " [ 2.1     -3.743   -0.829  ]\n",
            " [-0.5097   1.11635  0.09275]]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#multi-weight,multi-input,multi layered setup,with objects\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "X =[[1, 2, 3, 2.5],\n",
        "      [2.0,5.0,-1.0,2.0],\n",
        "        [-1.5,2.7,3.3,-0.8]]\n",
        "\n",
        "class layer_dense:\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights=0.10*np.random.randn(n_inputs,n_neurons) # the correct would have been 0.10*np.random.randn(n_neurons,n_inputs) but in the forward method we would have to do transpose so we did it here\n",
        "    self.biases=np.zeros((1,n_neurons)) # 1 is the shape and n_neurons is number of nuerons we want\n",
        "  def forward(self,inputs):\n",
        "       self.output=np.dot(inputs,self.weights)+self.biases\n",
        "\n",
        "layer1=layer_dense(4,5)\n",
        "layer2=layer_dense(5,5)\n",
        "\n",
        "layer1.forward(X)\n",
        "print(layer1.output)\n",
        "layer2.forward(layer1.output)\n",
        "print(layer2.output)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlEo_wu6I6vx",
        "outputId": "5d169fa3-62e2-4916-d6f5-57220693a325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
            " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
            " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
            "[[-0.18969615  0.03342147 -0.02578516  0.12739327  0.14946944]\n",
            " [-0.1128111   0.00125844 -0.0290323   0.1678249   0.05300012]\n",
            " [ 0.03961535 -0.07700061 -0.11111625  0.12960619 -0.02794614]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's add a activation function basically turns the linear function into a curve to be able to calculate the lowest point\n",
        "# example RELU\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "X =[[1, 2, 3, 2.5],\n",
        "      [2.0,5.0,-1.0,2.0],\n",
        "        [-1.5,2.7,3.3,-0.8]]\n",
        "\n",
        "inputs =[0,2,-1,3.3,-2.7,1.1,2.2,-100]\n",
        "output=[]\n",
        "for i in inputs:\n",
        "  output.append(max(0,i))\n",
        "print(output)"
      ],
      "metadata": {
        "id": "e24H9cNR4c5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f26b70-f1a7-4e81-a63f-11eedeaa5115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 0, 3.3, 0, 1.1, 2.2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import KeysView\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "X = [[1, 2, 3, 2.5],\n",
        "     [2.0, 5.0, -1.0, 2.0],\n",
        "     [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "class LayerDense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "\n",
        "class relu:\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.maximum(0,inputs)\n",
        "\n",
        "j = int(input(\"what is the number of hidden layers? \"))\n",
        "k = int(input(\"what is the number of outputs? \"))\n",
        "\n",
        "layer1 = LayerDense(4, j)\n",
        "layer2 = LayerDense(j, k)\n",
        "\n",
        "layer1.forward(X)\n",
        "layer2.forward(layer1.output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tow2Wk_Ehvrw",
        "outputId": "a6561805-feaa-434e-a5cb-9b0dd98af280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the number of hidden layers? 3\n",
            "what is the number of outputs? 2\n",
            "[[0.13008869 0.02097984]\n",
            " [0.15932724 0.05289362]\n",
            " [0.         0.03183967]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLw6QjXrzJeP",
        "outputId": "5196b5f5-f440-4e7a-fe65-78b7d03b9cf2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nnfs in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnfs) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import KeysView\n",
        "import numpy as np\n",
        "import nnfs\n",
        "nnfs.init()\n",
        "from nnfs.datasets import spiral_data\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "X, y = spiral_data(100, 3)\n",
        "class layer_output:\n",
        "  def __init__(self,n_inputs,n_neurona):\n",
        "    self.weights=0.10*np.random.randn(n_inputs,n_neurona)\n",
        "    self.biases=np.zeros((1,n_neurona))\n",
        "  def forward(self,inputs):\n",
        "    self.ouputs=np.dot(inputs,self.weights)+self.biases\n",
        "\n",
        "class RELU:\n",
        "  def forward(self,inputs):\n",
        "    self.outputs=np.maximum(0,inputs)\n",
        "\n",
        "k= int(input(\"enter the number of neurons\"))\n",
        "layer1=layer_output(2,k)\n",
        "activation1=RELU()\n",
        "layer1.forward(X)\n",
        "activation1.forward(layer1.ouputs)\n",
        "print(activation1.outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WStuDcXpx4J8",
        "outputId": "07a124de-1c7e-4707-ed27-95140facf469"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the number of neurons7\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.00116596 0.         ... 0.00123928 0.         0.        ]\n",
            " [0.         0.00321554 0.         ... 0.00253564 0.         0.        ]\n",
            " ...\n",
            " [0.09229197 0.         0.00745169 ... 0.         0.017093   0.10952952]\n",
            " [0.1473361  0.         0.01386877 ... 0.         0.06133506 0.1411885 ]\n",
            " [0.07827959 0.         0.00582034 ... 0.         0.00586882 0.10143228]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax activation function"
      ],
      "metadata": {
        "id": "w02-QIwr3vb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax activation function hardcode\n",
        "import math\n",
        "E= math.e\n",
        "output=[2.44,5.22,5.8594]\n",
        "\n",
        "exp=[]\n",
        "for i in output:\n",
        "  exp.append(E**i)\n",
        "print(exp)#exponantiation\n",
        "\n",
        "\n",
        "norm_base=sum(exp)\n",
        "norm=[]\n",
        "for i in exp:\n",
        "  norm.append(i/norm_base)\n",
        "print(norm)#normalisation\n",
        "\n",
        "print(sum(norm))"
      ],
      "metadata": {
        "id": "E6haTkMU323z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043986b4-7606-4bb9-8e44-6b6742bf8ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11.473040742794831, 184.93418407068333, 350.5137726512231]\n",
            "[0.020977510090084465, 0.3381369245795306, 0.640885565330385]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "\n",
        "layer_outputs= [[4.8,1.21,2.385],\n",
        "                [8.9,-1.81,0.2],\n",
        "                [1.41,1.051,0.026]]\n",
        "exp_values = np.exp(layer_outputs)\n",
        "normal_val= exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
        "print(normal_val)\n",
        "'''exp_values = np.exp(layer_outputs)\n",
        "print(exp_values)\n",
        "\n",
        "normal_val= exp_values/np.sum(exp_values)\n",
        "print(normal_val)'''"
      ],
      "metadata": {
        "id": "nysyk-x7DYTW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bea321da-0e59-4a85-91ca-fefd0a938557"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
            " [9.99811129e-01 2.23163963e-05 1.66554348e-04]\n",
            " [5.13097164e-01 3.58333899e-01 1.28568936e-01]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'exp_values = np.exp(layer_outputs)\\nprint(exp_values)\\n\\nnormal_val= exp_values/np.sum(exp_values)\\nprint(normal_val)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import KeysView\n",
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "np.random.seed(0)\n",
        "\n",
        "class LayerDense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.outputs = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "\n",
        "class RELU:\n",
        "    def forward(self, inputs):\n",
        "        self.outputs = np.maximum(0, inputs)\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))  # Subtract max for numerical stability\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "        self.outputs = probabilities\n",
        "\n",
        "\n",
        "# User input for neurons in the layers\n",
        "k = int(input(\"Enter the number of neurons in the first layer: \"))\n",
        "p = int(input(\"Enter the number of neurons in the output layer: \"))\n",
        "\n",
        "# Generate dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Forward pass through the first layer\n",
        "layer1 = LayerDense(2, k)\n",
        "activation1 = RELU()\n",
        "layer1.forward(X)\n",
        "activation1.forward(layer1.outputs)\n",
        "\n",
        "# Forward pass through the second layer\n",
        "layer2 = LayerDense(k, p)\n",
        "layer2.forward(activation1.outputs)\n",
        "\n",
        "# Forward pass through softmax activation\n",
        "activation2 = Softmax()\n",
        "activation2.forward(layer2.outputs)\n",
        "\n",
        "# Print the softmax output\n",
        "print(\"Softmax output:\")\n",
        "print(activation2.outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtzPmP4I5M45",
        "outputId": "8233cf07-73c0-4e73-ca7d-13ee55fe8aca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of neurons in the first layer: 9\n",
            "Enter the number of neurons in the output layer: 7\n",
            "Softmax output:\n",
            "[[0.14285715 0.14285715 0.14285715 ... 0.14285715 0.14285715 0.14285715]\n",
            " [0.14287454 0.14284727 0.14283878 ... 0.14284484 0.14287548 0.14284901]\n",
            " [0.14287461 0.14283906 0.14287437 ... 0.14285246 0.14290208 0.14280756]\n",
            " ...\n",
            " [0.1457957  0.14330728 0.14088179 ... 0.14116937 0.14439568 0.14134444]\n",
            " [0.14618595 0.14435534 0.141594   ... 0.14108536 0.14362057 0.14140147]\n",
            " [0.14571458 0.14303394 0.14067398 ... 0.1411752  0.14460658 0.14132953]]\n"
          ]
        }
      ]
    }
  ]
}